\documentclass[6008notes.tex]{subfiles}
\begin{document}
\graphicspath{ {images/conditioning/} }

\section{Conditioning on Events}

\subsection{Conditioning on Events Intro}

TODO -- add notes from video

% OK, now let's move on to talk about the next important concept called conditioning. In practice, we often encounter this kind of situation in that we have a probability model for some situation, but then we made some observation or something happened, and it changed this probability model. For example, you will observe that it was raining today, then the probability of tomorrow being a rainy day would certainly change. If we observed some information about a certain company today, then the probability that its stock price would increase tomorrow would be different. How do we address this in our formal mathematical language? This is about conditioning. Now let's go back to this familiar picture of a general sample space, Omega. Suppose we have a probability model all built up. Let's call that (Omega, P). And there are two events in general A and B. They could have some intersection. And depending on where the outcome falls, we say event A occurs, event B occurs, or both A and B occur. So that's a familiar picture. Now, suppose that we have an observation that A occurred. What does that mean? That means the outcome of the random experiment, omega-- we know that it lies in A. Now this would change the picture. How does it change the picture is that we should not be worrying about this overall sample space anymore. Anything out of A: we don't care. Because they don't happen anymore. This is the only thing that we should be worrying about. And here we still have a set A that becomes our new sample space. We still have-- the set from Omega now changed to A-- we still have the set of possible outcomes. We still don't know exactly where the outcome would be. And therefore, there should be a new sample space, a new model, and a new probability assignment. The original: Let's call that P. Now this new one we'll call that P conditioned on A. This is the probability-- the conditional probability, conditioned on "event A occurs". Now how would we write this out mathematically? For any omega, any possible outcome from the original picture, the probability of this particular outcome conditioned on A: There could be two different cases. If omega is not in A, then that would change into-- If you observe A, that means omega has to be in A. But for any omega that's not in A, that's never going to occur anymore. So the probability goes to 0. And that if omega is in A, we have probability of omega of this. Well, this should be-- the chance with this particular outcome should increase. We write that as probability, the original probability of this divided by probability of event A. Why do we want to scale with this 1 over P of A? This is so that to guarantee sum over all the omega in this A, this new sample space-- this new space of all possible outcome-- probability of omega conditional A. That's precisely equal to 1. We scale everything up, renormalize this so that we get a valid probability assignment on this new sample space, which was A.

\subsection{The Product Rule for Events}

TODO -- add notes from video

% This is the summary that conditioning is this picture that took we call from a sample space here in black. And if we observe an event A occur, then we move on to this red part, meaning my sample space turned from Omega to A. And my probability turned from P to the conditional probability of something given A. And we have given this nice little formula here. Well, this is actually a good opportunity that we should start to avoid writing probability in this way. The part we shouldn't like is the probability of omega of a particular outcome. As we said that, we should always think of probability of some kind of event. So when I write an omega, I'm thinking of a single element event-- a set with only one element omega. A better way of writing this is to look at probability another event B given A. Given that you observe A occurs, what's to probability for B to occur? Well, given A occurs then we keep our focus on this red part, and the only way for B to occur is that the random experiment given outcome in this area, in this intersection, A intersect B part. Every outcome here has a probability of P of that outcome and now raised up by 1 over A. So we can write out this definition as probability of A intersect B divided by probability of A. Probability of A remember is a number of less than 1, in general. So this raise up-- this probability is increased. This is the definition of the conditional probability of B given A-- or conditioned on "A occurs". Alternative way of writing this is probability of A intersect B is equal to probability of A times probability of B condition of A. With the chance for A and B both occur, it's the probability that A occurs times B occurs conditioned A already occurred. And that this particular line is called the "product rule". You're going to see these two lines are exactly the same. This is the definition of the conditional probability. And this is called the product rule of how do you go back and forth between these two probability models, the original one and one conditioned on event A.


\subsection{Bayes' Theorem for Events}

\paragraph{Important note about dividing by probabilities:} We will often divide by probabilities. In videos, we might not always say this, but this is required: we cannot divide by 0. To ensure this, we will not condition on events that have probability 0.

Given two events $\mathcal{A}$ and $\mathcal{B}$ (both of which have positive probability), Bayes' theorem, also called Bayes' rule or Bayes' law, gives a way to compute $\mathbb {P}(\mathcal{A} | \mathcal{B})$ in terms of $\mathbb {P}(\mathcal{B} | \mathcal{A})$. This result turns out to be extremely useful for inference because often times we want to compute one of these, and the other is known or otherwise straightforward to compute.

Bayes' theorem is given by

{\centering$\mathbb {P}(\mathcal{A} | \mathcal{B}) = \frac{\mathbb {P}(\mathcal{B} | \mathcal{A}) \mathbb {P}(\mathcal{A})}{\mathbb {P}(\mathcal{B})}.$ \par}
 
The proof of why this is the case is a one liner:

{\centering$\mathbb {P}(\mathcal{A} | \mathcal{B}) \overset {(a)}{=} \frac{\mathbb {P}(\mathcal{A} \cap \mathcal{B})}{\mathbb {P}(\mathcal{B})} \overset {(b)}{=} \frac{\mathbb {P}(\mathcal{B} | \mathcal{A}) \mathbb {P}(\mathcal{A})}{\mathbb {P}(\mathcal{B})},$ \par}
 
where step $(a)$ is by the definition of conditional probability for events, and step $(b)$ is due to the product rule for events (which follows from rearranging the definition of conditional probability for $\mathbb {P}(\mathcal{B} | \mathcal{A})$).

\subsection{Practice Problem: Bayes' Theorem and Total Probability}

Your problem set is due in 15 minutes! It's in one of your drawers, but they are messy, and you're not sure which one it's in.

The probability that the problem set is in drawer $k$ is $d_k$. If drawer $k$ has the problem set and you search there, you have probability $p_k$ of finding it. There are a total of $m$ drawers.

Suppose you search drawer $i$ and do not find the problem set.

\begin{itemize}
\item (a) Find the probability that the paper is in drawer $j$, where $j \neq i$.

\item (b) Find the probability that the paper is in drawer $i$.
\end{itemize}

\paragraph{Solution:} Let $A_k$ be the event that the problem set is in drawer $k$, and $B_k$ be the event that you find the problem set in drawer $k$.

(a) We'll express the desired probability as $\mathbb {P}(A_ j|B_ i^ c)$. Since this quantity is difficult to reason about directly, we'll use Bayes' rule:

{\centering$\mathbb {P}(A_ j|B_ i^ c) = \frac{\mathbb {P}(B_ i^ c | A_ j) \mathbb {P}(A_ j)}{\mathbb {P}(B_ i^ c)}$ \par}
 
The first probability, $\mathbb {P}(B_ i^ c | A_ j)$, expresses the probability of not finding the problem set in drawer $i$ given that it's in a different drawer $j$. Since it's impossible to find the paper in a drawer it isn't in, this is just 1.

The second quantity, $\mathbb {P}(A_ j)$, is given to us in the problem statement as $d_j$.

The third probability, $\mathbb {P}(B_ i^ c) = 1-\mathbb {P}(B_ i)$, is difficult to reason about directly. But, if we knew whether or not the paper was in the drawer, it would become easier. So, we'll use total probability:

\begin{eqnarray*}
            \mathbb{P}(B_i) &=& \mathbb{P}(B_i|A_i)\mathbb{P}(A_i) + \mathbb{P}(B_i|A_i^c)\mathbb{P}(A_i^c) \\
            &=& p_i d_i + 0 (1-d_i)
\end{eqnarray*}

Putting these terms together, we find that

{\centering$\mathbb {P}(A_ j|B_ i^ c) = \frac{d_ j}{1-p_ i d_ i}$ \par}
 
\paragraph{Alternate method to compute the denominator $\mathbb {P}(B_ i^ c)$:} We could use the law of total probability to decompose $\mathbb {P}(B_ i^ c)$ depending on which drawer the homework is actually in. We have

\begin{eqnarray*}
        \mathbb{P}(B_i^c) &=& \sum_{k=1}^m
                       \underbrace{\mathbb{P}(A_k)}_{d_k}
                       \underbrace{\mathbb{P}(B_i^c|A_k)}_{\substack{1\text{ if }k\ne i,\\
                                                             (1-p_i)\text{ if }k=i}} \\
                  &=& \sum_{\substack{k=1,\\
                                     k\ne i}}^m d_k
                     + (1-p_i)d_i \\
                  &=& \sum_{k=1}^m d_k - p_i d_i \\
                  &=& 1 - p_i d_i.
\end{eqnarray*}

(b) Similarly, we'll use Bayes' rule:

{\centering$\mathbb {P}(A_ i | B_ i^ c) = \frac{\mathbb {P}(B_ i^ c | A_ i) \mathbb {P}(A_ i)}{\mathbb {P}(B_ i^ c)} = \frac{(1-p_ i) d_ i}{1 - p_ i d_ i}$ \par}
 
\subsection{Take-Away Lessons:}

\begin{itemize}
\item Defining the sample-space is not always going to help solve the problem. (It's difficult to precisely define the sample space for this particular problem)

\item When in doubt of being able to precisely define the sample space, try to define events intelligently, i.e., in a way that you use what you're given in the problem.

\item The probability law of a probability model is a function on events, or subsets of the sample space, i.e., one can work with the probability law without knowing precisely what the sample-space (as a set) is.
\end{itemize}


\end{document}