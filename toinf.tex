\documentclass[6008notes.tex]{subfiles}
\begin{document}
\graphicspath{ {images/toinf/} }

\section{Towards Infinity in Modeling Uncertainty}

\subsection{Infinite Outcomes}

What if we want an infinite number of outcomes? For example, consider an underlying experiment where we keep flipping a coin until we see the first heads. We might have to flip an arbitrarily large number of tosses! Here, the sample space would consist of getting heads for the first time after 1 toss, after 2 tosses, and so forth, ad infinitum.

On a computer, we can't actually store an arbitrary probability table with an infinite number of entries.

A few workarounds:

\begin{itemize}
\item Approximate the probability distribution with a finite probability space.

\item In the above example, we could for example truncate and lump together all the possible outcomes in which heads appears after the 1000-th toss into a single possible outcome; we lose the ability to reason about the first heads appearing on, say, the 2000-th toss, but we could argue that heads appearing after the 1000th toss is extremely rare anyways.

\item For very specific probability distributions, there can be a way for us to represent the distribution ``in closed form'' meaning that if we just keep track of a few numbers, these few numbers are enough to tell us what the probability is for any possible outcome in an infinitely large sample space.
\end{itemize}

Recall that the binomial distribution is an example of this: with just two numbers, we can query any entry in a probability table with far more than just two entries!

\subsection{The Geometric Distribution}

We now give an example of a distribution with an infinite alphabet size called the geometric distribution that has only 1 parameter. Thus, storing 1 number tells you what all the probability table entries are, even though there are an infinite number of entries!

Let's say I have some experiment that succeeds with some probability. How many times do I have to run independent trials of this experiment until I see the first success? 

I have a biased coin, where if I toss it, the probability of heads $\mathbb{P}(H) = p$. I'm going to keep tossing this coin until I see the first heads. What are the possible outcomes? Well, it could be that I get heads in one toss, or I get tails and then I get heads, or I get 2 tails and then heads, and so forth. So our sample space is:

{\centering$\Omega = \{ H, TH, TTH, \dots \}$ \par}

We're going to assign probabilities to each of these outcomes. The probability of heads in one toss is just $\mathbb{P}(H) = p$. The probability of tails and then heads? Since the tosses are independent,

\begin{eqnarray*}
\mathbb{P}(TH) &=& \mathbb{P}(tails 1st)\mathbb{P}(heads 2nd) \\
							 &=& (1-p) \cdot p
\end{eqnarray*}

Similarly, the probability of 2 tails and then a heads is going to be $\mathbb{P}(TH) = (1-p)^2 \cdot p$and so on.

But return to the original question, ``how many tosses until the first heads?'' We can phrase that in terms of a random variable $X$, the number of tosses until we see the first heads. The possible outcomes are, of course, $\mathcal{X} = \{1, 2, 3, \dots \}$, the set of positive integers. This is the alphabet of random variable $X$, the possible values that random variable $X$ can take on. 

As a reminder, a random variable is a function that maps from the sample space to this alphabet, $X: \Omega \rightarrow \mathcal(X)$. $X$ takes as input an element in the sample space, for example, heads. Then $X(H) = 1$ because this is heads in one toss. And similarly, Then $X(TH) = 2$, because we have two tosses until the first heads. And so forth. 

So what is $\mathbb{P}(X = x)$? $X = x$ is shorthand: 

{\centering$\{X = x\} \Longleftrightarrow \{ \omega \in \Omega : X(\omega) = x \}$ \par}

For example, if $x = 1$, then we're looking at all possible outcomes in the sample space for which X of that outcome, is 1. So there's only one possible answer there, which is "H". 

By doing this mapping, you can see that

\begin{eqnarray*}
\mathbb{P}(X = x) &=& \mathbb{P}(x-1 tails followed by heads) \\
									&=& (1-p)^{x-1} \cdot p \qquad x = 1, 2, \dots
\end{eqnarray*}

This is called the probability mass function of random variable $X$. In particular, it is the probability mass function of a geometric random variable with parameter $p$. So we denote that by saying $x$ is distributed as geometric with parameter $p$, $X \sim \text {Geo}(p)$. It is referred to as a geometric distribution because of the geometric decay in this probability as you increase $x$.


\subsection{Practice Problem: The Geometric Distribution}

Let $X \sim \text {Geo}(p)$ so that

{\centering$p_ X(x) = (1-p)^{x-1} p\qquad \text {for }x=1, 2, \dots$ \par}
 
\begin{itemize}
\item Show that each of the table entries $p_X(x)$ is nonnegative for $x = 1, 2, \dots$.
\end{itemize}

\paragraph{Solution: } Note that $(1-p) \ge 0$, $x-1 \ge 0$, and $p \ge 0$, and so $(1-p)^{x-1}p \ge 0$ for all $p \in (0,1)$ and $x=1,2,3,\dots$

\begin{itemize}
\item Show that the sum of all the table entries is 1, i.e., $\sum _{x=1}^\infty p_ X(x) = 1$.
\end{itemize}

You may find the following result from calculus helpful: For $r\in (-1,1)$,

{\centering$\sum _{i=0}^{\infty }r^{i}=\frac{1}{1-r}.$ \par}

\paragraph{Solution: } For $p \in (0,1)$,

{\centering$\sum _{x=1}^{\infty }p_{X}(x)=\sum _{x=1}^{\infty }(1-p)^{x-1}p\overset {(a)}{=}p\sum _{i=0}^{\infty }(1-p)^{i}\overset {(b)}{=}p\cdot \frac{1}{1-(1-p)}=p\cdot \frac{1}{p}=1,$ \par}
 
where step $(a)$ substitutes $i=x-1$, and step $(b)$ uses the result above from calculus.


\subsection{Discrete Probability Spaces and Random Variables}

In the case of the geometric distribution, the sample space $\Omega$ is what's called ``countably infinite''. This means that it has an infinite (rather than finite) number of entries, and that there's actually a way for us to arrange the elements so that there's a 1st element, 2nd, 3rd, and so forth off into infinity. Note that the set of real numbers is not countable.

Before this section, every time we used the phrases ``probability space'' and ``random variable'', we actually meant ``finite probability space'' and ``finite random variable''.

More general than the finite probability space and finite random variable are the discrete probability space and discrete random variable:

\paragraph{Definition of a ``discrete probability space'':} A discrete probability space $(\Omega ,\mathbb {P})$ is the same thing as a finite probability space except that the sample space $\Omega$ is allowed to be either finite or countably infinite. In particular, a discrete probability space consists of two ingredients:

a finite or countably infinite sample space $\Omega$ that is the collectively exhaustive, mutually exclusive set of all possible outcomes

an assignment of probability $\mathbb {P}$, where for any outcome $\omega \in \Omega$, we have $\mathbb {P}(\text {outcome }\omega )$ be a number at least 0 and at most 1, and

{\centering$\sum _{\omega \in \Omega }\mathbb {P}(\text {outcome }\omega )=1.$ \par}
 
\paragraph{Definition of a ``discrete random variable'':} A discrete random variable $X$ is the same thing as a finite random variable except that it's associated with a discrete probability space rather than a finite probability space. In particular, given a discrete probability space $(\Omega ,\mathbb {P})$, a discrete random variable $X$ maps $\Omega$ to a set of values $\mathcal{X}$ that the random variable can take on. Again, we can think of such a random variable $X$ as generated from a two step procedure: some possible outcome $\omega$ is sampled from the discrete probability space $(\Omega ,\mathbb {P})$, and then $X$ takes on the value given by $X(\omega)$.

Formally defining random variables that are even more general than discrete random variables requires more sophisticated mathematical machinery that is beyond the scope of 6.008.1x.

\end{document}
