\contentsline {chapter}{\numberline {1}Probability and Inference}{3}{chapter.1}
\contentsline {section}{\numberline {1.1}Introduction to Probability}{3}{section.1.1}
\contentsline {subsection}{\numberline {1.1.1}Introduction}{3}{subsection.1.1.1}
\contentsline {subsection}{\numberline {1.1.2}A First Look at Probability}{3}{subsection.1.1.2}
\contentsline {paragraph}{Simulating Coin Flips}{3}{section*.2}
\contentsline {paragraph}{Computer note:}{5}{section*.3}
\contentsline {subsection}{\numberline {1.1.3}Probability and the Art of Modeling Uncertainty}{6}{subsection.1.1.3}
\contentsline {section}{\numberline {1.2}Probability Spaces and Events}{6}{section.1.2}
\contentsline {subsection}{\numberline {1.2.1}Two Ingredients to Modeling Uncertainty}{6}{subsection.1.2.1}
\contentsline {subsection}{\numberline {1.2.2}Probability Spaces}{7}{subsection.1.2.2}
\contentsline {paragraph}{Notation:}{7}{section*.4}
\contentsline {paragraph}{Why finite?}{7}{section*.5}
\contentsline {subsection}{\numberline {1.2.3}Table Representation}{8}{subsection.1.2.3}
\contentsline {subsection}{\numberline {1.2.4}More on Sample Spaces}{8}{subsection.1.2.4}
\contentsline {subsection}{\numberline {1.2.5}Probabilities with Events}{8}{subsection.1.2.5}
\contentsline {subsection}{\numberline {1.2.6}Events as Sets}{9}{subsection.1.2.6}
\contentsline {subsection}{\numberline {1.2.7}Code for Dealing with Sets in Python}{9}{subsection.1.2.7}
\contentsline {subsection}{\numberline {1.2.8}Probabilities with Events and Code}{9}{subsection.1.2.8}
\contentsline {section}{\numberline {1.3}Random Variables}{9}{section.1.3}
\contentsline {subsection}{\numberline {1.3.1}A First Look at Random Variables}{9}{subsection.1.3.1}
\contentsline {subsection}{\numberline {1.3.2}Random Variables}{10}{subsection.1.3.2}
\contentsline {paragraph}{Definition of a ``finite random variable'' (in this course, we will just call this a ``random variable''):}{11}{section*.6}
\contentsline {paragraph}{Quick summary:}{11}{section*.7}
\contentsline {paragraph}{Explanation using a picture:}{11}{section*.8}
\contentsline {paragraph}{Technical note:}{11}{section*.9}
\contentsline {subsection}{\numberline {1.3.3}Random Variables Notation and Terminology}{12}{subsection.1.3.3}
\contentsline {section}{\numberline {1.4}Jointly Distributed Random Variables}{12}{section.1.4}
\contentsline {subsection}{\numberline {1.4.1}Relating Two Random Variables}{12}{subsection.1.4.1}
\contentsline {paragraph}{Conceptual note:}{13}{section*.10}
\contentsline {paragraph}{Preview of inference:}{13}{section*.11}
\contentsline {subsection}{\numberline {1.4.2}Representing a Joint Probability Table in Code}{14}{subsection.1.4.2}
\contentsline {paragraph}{Approach 0:}{14}{section*.12}
\contentsline {paragraph}{Approach 1:}{14}{section*.13}
\contentsline {paragraph}{Approach 2:}{15}{section*.14}
\contentsline {paragraph}{Some remarks:}{16}{section*.15}
\contentsline {subsection}{\numberline {1.4.3}Marginalization}{16}{subsection.1.4.3}
\contentsline {paragraph}{Marginalization:}{17}{section*.16}
\contentsline {subsection}{\numberline {1.4.4}Marginalization for Many Random Variables}{17}{subsection.1.4.4}
\contentsline {subsection}{\numberline {1.4.5}Conditioning for Random Variables}{19}{subsection.1.4.5}
\contentsline {paragraph}{Conditioning:}{19}{section*.17}
\contentsline {paragraph}{Computational interpretation:}{19}{section*.18}
\contentsline {subsection}{\numberline {1.4.6}Moving Toward a More General Story for Conditioning}{20}{subsection.1.4.6}
\contentsline {section}{\numberline {1.5}Conditioning on Events}{20}{section.1.5}
\contentsline {subsection}{\numberline {1.5.1}Conditioning on Events Intro}{20}{subsection.1.5.1}
\contentsline {subsection}{\numberline {1.5.2}The Product Rule for Events}{20}{subsection.1.5.2}
\contentsline {subsection}{\numberline {1.5.3}Bayes' Theorem for Events}{20}{subsection.1.5.3}
\contentsline {paragraph}{Important note about dividing by probabilities:}{20}{section*.19}
\contentsline {subsection}{\numberline {1.5.4}Practice Problem: Bayes' Theorem and Total Probability}{20}{subsection.1.5.4}
\contentsline {paragraph}{Solution:}{21}{section*.20}
\contentsline {paragraph}{Alternate method to compute the denominator $\mathbb {P}(B_ i^ c)$:}{21}{section*.21}
\contentsline {subsection}{\numberline {1.5.5}Take-Away Lessons:}{21}{subsection.1.5.5}
\contentsline {section}{\numberline {1.6}Inference with Bayes' Theorem for Random Variables}{22}{section.1.6}
\contentsline {subsection}{\numberline {1.6.1}The Product Rule for Random Variables (Also Called the Chain Rule)}{22}{subsection.1.6.1}
\contentsline {paragraph}{Interpretation:}{22}{section*.22}
\contentsline {paragraph}{Claim:}{22}{section*.23}
\contentsline {paragraph}{Proof:}{22}{section*.24}
\contentsline {paragraph}{Important convention for this course:}{22}{section*.25}
\contentsline {paragraph}{The product rule is symmetric:}{23}{section*.26}
\contentsline {paragraph}{Interpretation:}{23}{section*.27}
\contentsline {paragraph}{Many random variables:}{23}{section*.28}
\contentsline {subsection}{\numberline {1.6.2}Bayes' Rule for Random Variables (Also Called Bayes' Theorem for Random Variables}{23}{subsection.1.6.2}
\contentsline {paragraph}{Bayes' theorem:}{24}{section*.29}
\contentsline {paragraph}{Important:}{24}{section*.30}
\contentsline {paragraph}{Proof:}{24}{section*.31}
\contentsline {subsection}{\numberline {1.6.3}Bayes' Theorem for Random Variables: A Computational View}{24}{subsection.1.6.3}
\contentsline {subsection}{\numberline {1.6.4}Maximum A Posteriori (MAP) Estimation}{25}{subsection.1.6.4}
\contentsline {section}{\numberline {1.7}Independence Structure}{25}{section.1.7}
\contentsline {subsection}{\numberline {1.7.1}Independent Events}{25}{subsection.1.7.1}
\contentsline {subsection}{\numberline {1.7.2}Independent Random Variables}{26}{subsection.1.7.2}
\contentsline {paragraph}{Exercise: Independent Random Variables}{26}{section*.32}
\contentsline {subsection}{\numberline {1.7.3}Mutual vs Pairwise Independence}{27}{subsection.1.7.3}
\contentsline {subsection}{\numberline {1.7.4}Conditional Independence}{28}{subsection.1.7.4}
\contentsline {paragraph}{Part $(a)$:}{28}{section*.33}
\contentsline {paragraph}{Part $(b)$:}{29}{section*.34}
\contentsline {subsection}{\numberline {1.7.5}Explaining Away}{29}{subsection.1.7.5}
\contentsline {subsection}{\numberline {1.7.6}Practice Problem: Conditional Independence}{31}{subsection.1.7.6}
\contentsline {section}{\numberline {1.8}Decisions and Expectations}{32}{section.1.8}
\contentsline {subsection}{\numberline {1.8.1}Introduction to Decision Making and Expectations}{32}{subsection.1.8.1}
\contentsline {subsection}{\numberline {1.8.2}The Expected Value of a Random Variable}{33}{subsection.1.8.2}
\contentsline {paragraph}{Definition of expected value:}{34}{section*.35}
\contentsline {subsection}{\numberline {1.8.3}Variance and Standard Deviation}{35}{subsection.1.8.3}
\contentsline {subsection}{\numberline {1.8.4}Practice Problem: The Law of Total Expectation}{35}{subsection.1.8.4}
\contentsline {paragraph}{Solution:}{35}{section*.36}
\contentsline {section}{\numberline {1.9}Measuring Randomness}{36}{section.1.9}
\contentsline {subsection}{\numberline {1.9.1}Introduction to Information-Theoretic Measures of Randomness}{36}{subsection.1.9.1}
\contentsline {subsection}{\numberline {1.9.2}Shannon Information Content}{37}{subsection.1.9.2}
\contentsline {subsection}{\numberline {1.9.3}Shannon Entropy}{37}{subsection.1.9.3}
\contentsline {paragraph}{Notation:}{38}{section*.37}
\contentsline {subsection}{\numberline {1.9.4}Information Divergence}{38}{subsection.1.9.4}
\contentsline {subsection}{\numberline {1.9.5}Proof of Gibbs' Inequality}{40}{subsection.1.9.5}
\contentsline {paragraph}{Gibbs' inequality:}{40}{section*.38}
\contentsline {paragraph}{Proof:}{40}{section*.39}
\contentsline {paragraph}{Claim:}{41}{section*.40}
\contentsline {paragraph}{Proof:}{41}{section*.41}
\contentsline {subsection}{\numberline {1.9.6}Mutual Information}{42}{subsection.1.9.6}
\contentsline {subsection}{\numberline {1.9.7}Exercise: Mutual Information}{42}{subsection.1.9.7}
\contentsline {subsection}{\numberline {1.9.8}Information-Theoretic Measures of Randomness: Where We'll See Them Next}{43}{subsection.1.9.8}
\contentsline {section}{\numberline {1.10}Towards Infinity in Modeling Uncertainty}{43}{section.1.10}
\contentsline {subsection}{\numberline {1.10.1}Infinite Outcomes}{43}{subsection.1.10.1}
\contentsline {subsection}{\numberline {1.10.2}The Geometric Distribution}{44}{subsection.1.10.2}
\contentsline {subsection}{\numberline {1.10.3}Practice Problem: The Geometric Distribution}{44}{subsection.1.10.3}
\contentsline {paragraph}{Solution: }{44}{section*.42}
\contentsline {paragraph}{Solution: }{44}{section*.43}
\contentsline {subsection}{\numberline {1.10.4}Discrete Probability Spaces and Random Variables}{44}{subsection.1.10.4}
\contentsline {paragraph}{Definition of a ``discrete probability space'':}{45}{section*.44}
\contentsline {paragraph}{Definition of a ``discrete random variable'':}{45}{section*.45}
\contentsline {chapter}{\numberline {2}Graphical Models}{46}{chapter.2}
\contentsline {chapter}{\numberline {3}Learning a Probabilistic Model from Data}{47}{chapter.3}
\contentsline {chapter}{\numberline {A}Notation Summary}{48}{appendix.A}
